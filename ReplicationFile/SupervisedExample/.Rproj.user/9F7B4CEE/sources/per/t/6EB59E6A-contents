##Grimmer and Stewart
## ``Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts"

##Replication of Supervised Learning Example
##Based off of previously published research Stewart & Zhukov (2008)

set.seed(02138)
library(randomForest)
library(e1071)

##Load the Data
data <- read.delim('TFIDFLSA.csv', sep=',')
training <- read.delim('TrainingData.csv', sep=',')
training <- training[,c(2,3,4)]



##Running the RandomForest
##Import Features and Training Information

	##Dataset of Only Known Data
	x <- cbind(training, data)
	x <- x[which(x$TRAININGSET_SELECTION==1),]
	x$TRAININGSET_VALUE <- as.factor(x$TRAININGSET_VALUE)

	##Seperate Test and Training Data
	trainingsubset <- x
	
	##Define Random Forest Inputs x, y, xtest, ytest
	x <- trainingsubset[,-c(1,2,3,4)] ##Matrix of Predictors
	y <- trainingsubset[,2] ## Response Vector: 2 for Use of Force, 3 for Issue

##Computationally expensive steps to determine optimal parameters using CV
results <- tune(randomForest, train.x=x, train.y=y, 
                ranges=list(mtry=c(3:20), ntree=seq(from=50, to=1000, by=50)),
                tune.control(random=TRUE, sampling="cross",cross=5))
plot(results)

##Run a set of parameters based on CV
set.seed(02138) 
#Note that R2.14.1 with comparable randomForest package version is necessary for exact 
#replication of paper results.  They are very slightly different with newer versions of R. 
check <- tune(randomForest, train.x=x, train.y=y, 
                ranges=list(mtry=15, ntree=500),
                tune.control(random=TRUE, sampling="cross",cross=10))


tables <- list()
for (i in 1:10) {
  samp <- check$train.ind[[i]]
  results <- randomForest(x=x[samp,], y=y[samp], mtry=15, ntree=500)
  
  RFpredictions <- predict(results, newdata=x[-samp,], type="response")
  tables[[i]] <- table( RFpredictions, y[-samp])
}

confusion <- tables[[1]]
for (i in 2:10) {
  confusion <- confusion + tables[[i]]
}
library(xtable)
xtable(confusion)


results <- randomForest(x=x, y=y, mtry=15, ntree=500)
RFpredictions <- predict(results, newdata=data[,-1], type="response")

OtherData <- read.delim('090206_cm.csv', sep=',', header=T) 
m1 <- as.data.frame(cbind(DOCUMENT_ID=as.character(data[,1]), RFpredictions))
m1$DOCUMENT_ID <- gsub("Docs\\\\","",m1$DOCUMENT_ID)
m2 <- merge(m1, OtherData, by.x = "DOCUMENT_ID", by.y = "DOCUMENT_ID", all.x=FALSE, all.y=FALSE)  


#Components for Table 3: Classifications by Elite Type
table(m2$RFpredictions[m2$MILT==1])
table(m2$RFpredictions[m2$MILT==0])

table(m2$RFpredictions[m2$MILT==1])/length(m2$RFpredictions[m2$MILT==1])
table(m2$RFpredictions[m2$MILT==0])/length(m2$RFpredictions[m2$MILT==0])

table(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==1])
table(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==0])
table(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==1])/length(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==1])
table(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==0])/length(m2$TRAININGSET_VALUE[m2$TRAININGSET_SELECTION==1 & m2$MILT==0])


